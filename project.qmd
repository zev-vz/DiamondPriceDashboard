---
title: "Predicting (Diamond) Prices"
format: 
  html:
    self-contained: true
author:
- Zev van Zanten
---

## Setup

Note: ChatGPT was consulted throughout, primarily to write HTML code for custom

```{r setup, include = FALSE}
install.packages("glmnet")
```

## Introduction

For our project, we sought to do something that would let us integrate data visualization, data science models, and dashboards. These were the parts that we loved the most of anything we worked on in class and it made sense to combine them together.

We went look looking for a helpful dataset already within R (while we could theoretically used APIs or webscraping to get data, we preferred not to). We came across the diamonds datset and quickly realized that it was perfect for what we wanted to do.

R's diamonds dataset - tucked away in the ggplot2 package - contains the sale information of 53,940 different diamonds. Each sale contains information on a diamond's price (in USD), size (in carats), length, width, height, cut (a qualitative and cardinal measure), color, and clarity.

First we decided to explore our data to understand what it looked like and to figure out what was most valuable to do with it. We decided to focus our exploratory analysis on patterns in price, color, cut, carats, and clarity as well as regressions between price and these specific variables.

The end result of this exploratory analysis were that there were a number of interesting patterns in the attributes of diamonds sold on the market. However, the most valuable (and interesting) thing was that a simple regression built with just four variables had a remarkable R\^2 of around 91%. This meant we could use our data to provide phenomenal predictive power. And each of the regression models we tested - which allowed us to envision different relationships and account for things like covariance - had a slightly different perspective.

Seeing this, it felt right to focus on creating an interactive visual display using a dashboard to give people information on the price of a specific diamond (as well as some other statistics for diamonds of this type).

```{r,echo=FALSE, message=FALSE, warning=FALSE}

#Loading Library
library(shiny)
library(ggplot2)
library(dplyr)
library(glmnet)
library(caret)
library(bslib)
library(patchwork)
```


```{r}

#Loading data
data("diamonds")

diamonds_named <- diamonds


#Getting basic look at data
print(diamonds)

#Summary stats for diamonds
summary(diamonds)

#Visualizations of distributions
# build each plot and give it a title
p1 <- ggplot(diamonds, aes(cut)) + geom_bar()           + ggtitle("Cut Distribution")
p2 <- ggplot(diamonds, aes(color)) + geom_bar()         + ggtitle("Color Distribution")
p3 <- ggplot(diamonds, aes(clarity)) + geom_bar()       + ggtitle("Clarity Distribution")
p4 <- ggplot(diamonds, aes(carat)) + geom_histogram()   + ggtitle("Carat Distribution")
p5 <- ggplot(diamonds, aes(price)) + geom_histogram()   + ggtitle("Price Distribution")
p6 <- ggplot(diamonds, aes(carat, price)) + geom_point() + ggtitle("Price vs. Carat")

# stitch them into 2 columns, 3 rows
( p1 + p2 ) /
( p3 + p4 ) /
( p5 + p6 )

#Creating regressions
#Linear regression model
lm_model <- lm(price ~ cut + color + clarity + carat, data = diamonds)

#Defining x and y so our next three regressions can work
x <- model.matrix(price ~ cut + color + clarity + carat, data = diamonds_named)[, -1]
y <- diamonds_named$price


#Classic ridge model to penalize less valuable models within our four predictive variables
ridge_model <- cv.glmnet(x, y, alpha = 0)

#Classic lasso model to take an alternate approach to building a more efficient model
lasso_model <- cv.glmnet(x, y, alpha = 1)

#Classic Elastic Regression to leverage the best of our lasso and ridge approaches
elastic_net_model <- cv.glmnet(x, y, alpha = 0.5)

#Classic polynomial model to see if that better fits the relationship in our data.
diamonds_named$carat2 <- diamonds_named$carat^2
poly_model <- lm(price ~ cut + color + clarity + carat + carat2, data = diamonds_named)

# Defining a function to calculate R^2 for three of my regressions
r2 <- function(actual, predicted) {
  1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)
}

# Computing R² for each model

lm_r2 <- summary(lm_model)$r.squared
poly_r2 <- summary(poly_model)$r.squared
ridge_r2 <- r2(y, predict(ridge_model, newx = x, s = "lambda.min"))
lasso_r2 <- r2(y, predict(lasso_model, newx = x, s = "lambda.min"))
enet_r2 <- r2(y, predict(elastic_net_model, newx = x, s = "lambda.min"))

# Combining all R² values into a list
r2_results <- list(
  Linear      = lm_r2,
  Polynomial  = poly_r2,
  Ridge       = ridge_r2,
  Lasso       = lasso_r2,
  ElasticNet  = enet_r2
)

# Printing the R^2 results
print(r2_results)
```

## Building the Dashboard

After settling on a dashboard for predicting the price of diamonds, we thought about what this dashboard should look like. Our central idea was that individuals should be able to input data to get a price as close to their situation as possible (meaning they should be able input carat, cut, color, and clarity.) We also wanted to help them understand the general data they were looking at, as we knew that just getting a dollar value was not the most helpful. As a result, we decided that rather than just getting an outputted number, our users should get the R\^2 value of the model they picked, the scatterplot itself, see where their point is within said scatterplot, and see the regression line.

We decided to include each of the five regressions as they were relatively similar in predictive power and could satisfy different needs/concerns of the user. The straightforward linear model gave them an idea of what their diamond was worth, while our Ridge, Lasso, and Elastic Net allowed them to avoid potential overfitting (if they were afraid of them.) And a polynomial model let them see how a different approach to the data changed the price.

To build our dashboard, we wound up taking an iterative approach that focused on building up our individual components and then stitching them together. First, we selected and constructed our different regressions and data visualizations as they were the basis of the entire dashboard. This was primarily regressions, though we also needed a scatterplot, labeled points, and a line.

After this, we identified the different filters and functions we would need to handle all our desired outputs and built them one by one. First, we built something that filtered all of our data according to specifications. Then we built a different function that would construct lines and other features from key inputs and another function that would extract R\^2.

With all the sub components built and ready, we stitched them together in a ShinyR database, using reactive functions and buttons to trigger most of them and finding opportunities to reduce code length and complexity whenever possible. We also stylized our overall dashboard using cards, HTML code (that we wrote with help from ChatGPT), and other odds and ends.

```{r,echo=FALSE, message=FALSE, warning=FALSE}
#We decided to make this a standalone chunk even though we could have relied on the previous chunk to make it more accessible and usable to a wider range of audiences.
# Loading different libraries that are necessary for the dashboard.
library(shiny)
library(ggplot2)
library(dplyr)
library(glmnet)
library(caret)
library(bslib)
```


```{r,message=FALSE, warning=FALSE}

# Loading the diamonds dataset
data("diamonds")
diamonds_named <- diamonds

# Preparing our matrix to fit the glmnet models
x <- model.matrix(price ~ cut + color + clarity + carat, data = diamonds_named)[, -1]
y <- diamonds_named$price

#Creating the linear model
lm_model <- lm(price ~ cut + color + clarity + carat, data = diamonds_named)
lm_r2 <- summary(lm_model)$r.squared

#Creating the Polynomial regression model (degree 2 on carat)
diamonds_named$carat2 <- diamonds_named$carat^2
poly_model <- lm(price ~ cut + color + clarity + carat + carat2, data = diamonds_named)
poly_r2 <- summary(poly_model)$r.squared

#Creating a Ridge regression model
ridge_model <- cv.glmnet(x, y, alpha = 0)
ridge_preds <- predict(ridge_model, newx = x, s = "lambda.min")
ridge_r2 <- 1 - sum((y - ridge_preds)^2) / sum((y - mean(y))^2)

#Creating a Lasso regression model
lasso_model <- cv.glmnet(x, y, alpha = 1)
lasso_preds <- predict(lasso_model, newx = x, s = "lambda.min")
lasso_r2 <- 1 - sum((y - lasso_preds)^2) / sum((y - mean(y))^2)

#Creating an Elastic Net regression model
elastic_net_model <- cv.glmnet(x, y, alpha = 0.5)
elastic_preds <- predict(elastic_net_model, newx = x, s = "lambda.min")
elastic_r2 <- 1 - sum((y - elastic_preds)^2) / sum((y - mean(y))^2)


# stash them in a named list for easy UI display
r2_values <- list(
  "Linear Regression"     = lm_r2,
  "Polynomial Regression" = poly_r2,
  "Ridge Regression"      = ridge_r2,
  "Lasso Regression"      = lasso_r2,
  "Elastic Net"           = elastic_r2
)

#Shiny UI helper function to make it easier to create all of our cards.

card_layout <- function(name, text, img) {
  #Specifying dimensions and other key features
  card(
   layout_column_wrap(
    width = 1/2, 
    responsive = TRUE,
    card_body(
      tags$p(tags$strong(name), text)
    ), 
    img(src = img, style = "width:100%; height:auto;")
  ), 
  class = "mb-4"
 )
}



#Creating the UI

ui <- fluidPage(
  #Title panel
  titlePanel("What's My Diamond Worth?", windowTitle = "Diamond Price Predictor"),
  tags$head(
    #HTML we wrote with help from ChatGPT to make our board more stylish
    tags$style(HTML("
      body {
        font-family: 'Arial', sans-serif;
        background-color: #f4f4f9;
      }
      .container {
        max-width: 1200px;
        margin: 0 auto;
      }
      .panel {
        background-color: white;
        padding: 20px;
        box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);
        border-radius: 8px;
      }
      .btn-primary {
        background-color: #007BFF;
        color: white;
        border: none;
      }
      .btn-primary:hover {
        background-color: #0056b3;
      }
      h1 {
        font-size: 30px;
        font-weight: 700;
        color: #2c3e50;
      }
      h3 {
        font-size: 22px;
        color: #34495e;
      }
      .text-muted {
        color: #7f8c8d;
      }
      .output {
        margin-top: 20px;
        font-size: 18px;
        color: #2c3e50;
      }
      .predictionPlot {
        width: 100%;
        max-height: 500px;
        margin-top: 20px;
      }
      .card {
        padding: 15px;
        border: 1px solid #e1e1e1;
        border-radius: 8px;
        background-color: #ffffff;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        margin-bottom: 20px;
      }
      .card-header {
        font-weight: bold;
        background-color: #f8f8f8;
        padding: 10px;
      }
    "))
  ),

  #Creatoing a layout for our sidebar, complete with choices and inputs pulled from our data to allow us to take inputs from users
  sidebarLayout(
    sidebarPanel(
      class = "panel",
      # user picks diamond specs
      div(class = "card", 
          div(class = "card-header", "Diamond Characteristics"),
          selectInput("cut_predict", "Cut:", choices = levels(diamonds_named$cut)),
          selectInput("color_predict", "Color:", choices = levels(diamonds_named$color)),
          selectInput("clarity_predict", "Clarity:", choices = levels(diamonds_named$clarity)),
          numericInput("carat_predict", "Carat:", value = 0.5, min = 0.2, max = 5, step = 0.01)
      ),
      # user picks model
      div(class = "card", 
          div(class = "card-header", "Select Model Type"),
          selectInput("model_type", "Model Type:", 
                      choices = names(r2_values),
                      selected = "Linear Regression")
      ),

      # only want confidence interval for linear/polynomial

      #Adding a conditional panel that lets users select a confidence level if they pick a certain type of compatible regression.

      conditionalPanel(
        condition = "input.model_type == 'Linear Regression' || input.model_type == 'Polynomial Regression'",
        sliderInput(
          "conf_level", "Confidence level:",
          min = 0.5, max = 0.99, value = 0.95, step = 0.01
        )
      ),

      #Enter buttons
      actionButton("predictButton", "Predict Price",
                   style = "background:transparent; border:2px solid #007BFF; color:#007BFF; margin-bottom:1rem;"),
      actionButton("infoButton", "More Info About Variables",
                   style = "background:transparent; border:2px solid #007BFF; color:#007BFF; margin-bottom:1rem;")
    ),

    #Our main panel for displaying stuff
    mainPanel(
      class = "container",
      h1("Diamond Price Prediction App"),
      textOutput("predictedPrice"), #Prediction
      textOutput("r2Text"), #R2 score
      div(class = "predictionPlot", plotOutput("predictionPlot")) #Show regression plot
    )
  )
)

#Creating the service side
server <- function(input, output) {
  # grab inputs when button clicked
  predict_inputs <- eventReactive(input$predictButton, {
    list(
      cut     = input$cut_predict,
      color   = input$color_predict,
      clarity = input$clarity_predict,
      carat   = input$carat_predict,
      model   = input$model_type
    )
  })
  # calculate the predicted price based on chosen model
  predicted_price <- eventReactive(input$predictButton, {
    inp <- predict_inputs()
    # build a tiny df for predict()
    df <- data.frame(
      cut     = factor(inp$cut,    levels = levels(diamonds_named$cut)),
      color   = factor(inp$color,  levels = levels(diamonds_named$color)),
      clarity = factor(inp$clarity,levels = levels(diamonds_named$clarity)),
      carat   = inp$carat
    )
    df$carat2 <- df$carat^2 # only poly needs this
    x_new     <- model.matrix(~ cut + color + clarity + carat, data = df)[, -1]

    #Allowing switching between models
    switch(inp$model,
      "Linear Regression"     = predict(lm_model, newdata = df),
      "Polynomial Regression" = predict(poly_model, newdata = df),
      "Ridge Regression"      = as.numeric(predict(ridge_model, newx = x_new, s = "lambda.min")),
      "Lasso Regression"      = as.numeric(predict(lasso_model, newx = x_new, s = "lambda.min")),
      "Elastic Net"           = as.numeric(predict(elastic_net_model, newx = x_new, s = "lambda.min"))
    )
  })

  # build a grid for plotting line + intervals

  fit_df <- eventReactive(input$predictButton, {
    inp <- predict_inputs()
    grid <- seq(0.2, 5, length.out = 100)
    df <- data.frame(
      cut     = factor(inp$cut, levels = levels(diamonds_named$cut)),
      color   = factor(inp$color, levels = levels(diamonds_named$color)),
      clarity = factor(inp$clarity, levels = levels(diamonds_named$clarity)),
      carat   = grid
    )
    df$carat2 <- df$carat^2
    xg <- model.matrix(~ cut + color + clarity + carat, data = df)[, -1]
    if (inp$model %in% c("Linear Regression", "Polynomial Regression")) {
      # prediction intervals if for linear regression or polynomial model
      fit_obj <- if (inp$model == "Linear Regression") lm_model else poly_model
      ci <- predict(fit_obj, newdata = df, interval = "prediction", level = input$conf_level)
      data.frame(carat = grid, fit = ci[,"fit"], lwr = ci[,"lwr"], upr = ci[,"upr"])
    } else {
      preds <- switch(inp$model,
        "Ridge Regression" = as.numeric(predict(ridge_model, newx = xg, s = "lambda.min")),
        "Lasso Regression" = as.numeric(predict(lasso_model, newx = xg, s = "lambda.min")),
        "Elastic Net"      = as.numeric(predict(elastic_net_model, newx = xg, s = "lambda.min"))
      )
      data.frame(carat = grid, fit = preds, lwr = preds, upr = preds)
    }
  })


  #Outputting a predicted price

  output$predictedPrice <- renderText({
    price <- predicted_price()
    paste0("The predicted price is: $", round(price, 2))
  })

  #Outputting a predicted r^2

  output$r2Text <- renderText({
    inp <- predict_inputs()
    r2 <- r2_values[[inp$model]]
    paste0("R² for ", inp$model, ": ", round(r2, 4))
  })


  #Rendering a plot for our outputted regression line and plot

  output$predictionPlot <- renderPlot({
    df_line <- fit_df()
    inp <- predict_inputs()
    pred_val <- predicted_price()
    #Creating the different parts of our regression line output
    ggplot() +
      geom_point(data = diamonds_named, aes(x = carat, y = price), alpha = 0.2, color = "gray") +
      geom_ribbon(data = df_line, aes(x = carat, ymin = lwr, ymax = upr), fill = "blue", alpha = 0.15) +
      geom_line(data = df_line, aes(x = carat, y = fit), size = 1) +
      annotate("point", x = inp$carat, y = pred_val, color = "red", size = 4) +
      labs(title = paste("Predicted Price Using", inp$model), x = "Carat", y = "Price ($)") +
      theme_minimal()
  })


  #Creating a more info button for interested users.

  observeEvent(input$infoButton, {
    showModal(modalDialog(
      title = "Variable Dictionary", size = "l", easyClose = TRUE,
      card_layout("Cut", "refers to how well the diamond has been shaped and faceted. A better cut enhances the diamond's brilliance and overall appearance.", 
        "https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.suratdiamond.com%2Fblog%2Fwp-content%2Fuploads%2F2021%2F02%2Fbrilliance-diamond-cut-chart.webp&f=1&nofb=1"),
      card_layout("Color", "refers to the absence of color in the diamond. The less color, the higher the value.", 
        "https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.brides.com%2Fthmb%2FGBtDWdJwsYmu17LqrVGm2lR49nU%3D%2F1500x0%2Ffilters%3Ano_upscale()%3Amax_bytes(150000)%3Astrip_icc()%2Fdiamond-color-chart-5093397_horizontal-b8d3872096fd47c78d244d40cc920099.png&f=1&nofb=1"),
      card_layout("Clarity", "measures the presence of internal or external imperfections. A clearer diamond is more valuable.", 
        "https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.blog1.trymintly.com%2Fwp-content%2Fuploads%2F2022%2F12%2Fdiamondbuzz.blog_.jpg&f=1&nofb=1"),
      card_layout("Carat", "measures the weight of the diamond. One carat is equivalent to 0.2 grams.", 
        "https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.diamondimports.com.au%2Fskin1%2Fimages%2Froundcarat.jpg&f=1&nofb=1"),
      footer = modalButton("Close")
    ))
  })
}

#Putting it all together.
shinyApp(ui = ui, server = server)
```


## Methods / Implementation

When building our dashboard, we chose to rely on Shiny as it was something had been taught in class and were familiar with. Regression models, too, were something primarily chosen because they were familiar enough to work with yet remained novel. The various bells and whistles were to make our dashboard more engaging and educational.

We also decided to use the built in linear regression models from R and the other 4 models from the glmnet package.

As soon as the code starts to run we created a model matrix x with all the predictors, and a response vectore y for the estimated price of a diamond. Then we fit the regression models for an Ordinary least squares (linear), Polynomial (adds a carat² term), Ridge (L2-penalized), Lasso (L1-penalized), and Elastic Net (mix of L1 & L2) model types. Next we got the r^2 or psuedo r^2 values. Then we stored all of the models r^2 values. Next we created a helper function for the card layout that would desplay all the helper information. Next we build the ui with a side bar layout containing all the needed inputs including a slider for a confidence interval that only appeared if you were using OLS or Polynomial models. Then when “Predict Price” is clicked, packages the user’s specs into a tiny data frame, chooses the right model, and returns a single price prediction. When this happens we also create a fitting grid by generating a sequence of carat values (0.2–5.0), using the selected model to predict over that grid (with prediction intervals for lm’s), and then building a data frame (df_line) for plotting the fit and ribbon. Lastly our site renders the the plot output with data point and line of best fit.

We decided to put our entire dashboard inside of a single chunk (rather an R file or some other form of storage) so that it was easily accessible within our report. To reproduce our results/to see our work, you can run either the chunk we used to test various things or the dashboard itself.


## Discussion & Conclusion

We envision our project having a number of helpful use cases and as a way to bring more clarity to the diamond market. For occasional people who don't usually engage in the diamond market but may do so occasionally (one or two times in their lifetime), this model helps them in negotiations. With a better understanding of what a diamond should be worth, they can counter the informational advantages that would previously put them at a disadvantage in the market. For example, something seeking to sell a diamond they inherited or a person looking to propose to their partner can get a better understanding of what they should ask for or what they should offer respectively. Even for individuals with more experience transacting in the diamond market (i.e., diamond merchants and jewelers), having a predictive model on hand can help them make better offers and make wiser choices of what prices to buy and sell for. Overall, our predictive model should be a powerful source of information that corrects potential flaws in the market.

Our analysis (and the model itself) shows that the vast majority of variety in diamond prices (about 90% across our five models) can be attributed to four simple factors: carat (size), color, cut, and clarity. This is incredibly valuable for anyone interested in understanding what affects the prices of diamonds and could even be extrapolated to help understand the pricing of jewelry as a whole (or anything that contains diamonds) by helping them understand some of the stuff influencing pricing. It also has value as something to help us understand what influences pricing.

In the end, we chose to make this because we were interested in the intersection of data science, data communication, and economics/business and saw this as the perfect way to work at the intersection of those interests while using a dataset that was accessible to everyone. It taught us a lot about the best practices in data communication (we spent hours experimenting with different dashboards) and data analysis (we spent a long time looking at and trying out different visualizations, and regressions). It also taught us a bunch of about best practices in writing and documenting code, in collaborating on data-based projects, and in product (and project) management.
